import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
from datetime import datetime
import os
import glob
import sys

# scripts í´ë”ë¥¼ ê²½ë¡œì— ì¶”ê°€í•˜ì—¬ ëª¨ë“ˆ ì„í¬íŠ¸ ê°€ëŠ¥í•˜ê²Œ ì„¤ì •
current_dir = os.path.dirname(os.path.abspath(__file__))
if current_dir not in sys.path:
    sys.path.append(current_dir)

from hospital_map_tab import render_hospital_map_tab

# --- [1. ê¸°ë³¸ í™˜ê²½ ì„¤ì •] ---
st.set_page_config(layout="wide", page_title="SFE Master Sandbox V13.1")

# --- [ìœ ë‹ˆí¬ íŒŒì¼ëª… ìƒì„± ìœ í‹¸ë¦¬í‹°] ---
def get_unique_filename(base_dir, base_name, ext):
    date_str = datetime.now().strftime('%y%m%d')
    base_path = os.path.join(base_dir, f"{base_name}_{date_str}")
    
    final_path = f"{base_path}.{ext}"
    if not os.path.exists(final_path):
        return final_path
    
    counter = 1
    while True:
        final_path = f"{base_path}({counter}).{ext}"
        if not os.path.exists(final_path):
            return final_path
        counter += 1

# --- [ìœ í‹¸ë¦¬í‹°: í•„ë“œ ë§¤í•‘ ë¡œë“œ/ì €ì¥] ---
def load_mapping_config():
    import json
    config_path = 'config/mapping.json'
    if os.path.exists(config_path):
        with open(config_path, 'r', encoding='utf-8') as f:
            return json.load(f)
    return {
        "ì§€ì ": ["ì§€ì ", "ì§€ì ëª…", "Branch"], 
        "ì„±ëª…": ["ì„±ëª…", "ë‹´ë‹¹ìëª…", "Rep", "ë‹´ë‹¹ì"], 
        "ë³‘ì›ëª…": ["ë³‘ì›ëª…", "ê±°ë˜ì²˜ëª…", "ìš”ì–‘ê¸°ê´€ëª…", "Hospital", "ê±°ë˜ì²˜"],
        "í’ˆëª©": ["í’ˆëª©", "í’ˆëª©ëª…", "Product"],
        "ì²˜ë°©ê¸ˆì•¡": ["ì²˜ë°©ê¸ˆì•¡", "ì‹¤ì ê¸ˆì•¡", "Amount", "ì‹¤ì "], 
        "ëª©í‘œê¸ˆì•¡": ["ëª©í‘œê¸ˆì•¡", "Target"],
        "ì›”": ["ì›”", "ëª©í‘œì›”", "Month"], 
        "activities": ["activities", "í™œë™", "í™œë™ëª…"], 
        "segment": ["segment", "ê·œëª¨", "ì¢…ë³„ì½”ë“œëª…"],
        "ë‚ ì§œ": ["ë‚ ì§œ", "í™œë™ì¼ì", "ëª©í‘œì›”", "Date"]
    }

def save_mapping_config(mapping_dict):
    import json
    config_path = 'config/mapping.json'
    os.makedirs(os.path.dirname(config_path), exist_ok=True)
    with open(config_path, 'w', encoding='utf-8') as f:
        json.dump(mapping_dict, f, ensure_ascii=False, indent=2)

def find_best_match(target_key, available_cols, mapping_dict):
    aliases = mapping_dict.get(target_key, [])
    for i, col in enumerate(available_cols):
        if col in aliases or col.lower() in [a.lower() for a in aliases]:
            return i
    return 0

# --- [2. 6ëŒ€ ë§ˆìŠ¤í„° ë¡œì§ ì—”ì§„ (Detailed Analytics)] ---
def calculate_master_engine(df, cfg):
    """
    êµ¬ì¬í˜„ ë‹˜ì˜ 12ëŒ€ ë§ˆìŠ¤í„° ë¡œì§ì„ ë°ì´í„°í”„ë ˆì„ì— ì£¼ì…í•©ë‹ˆë‹¤.
    """
    # [Logic 1] HIR & PI ê°€ì¤‘ì¹˜ ê¸°ì´ˆ ë§¤í•‘
    df['W_Act'] = df['activities'].map(cfg['hir_weights']).fillna(1.0)
    df['W_Seg'] = df['segment'].map(cfg['pi_weights']).fillna(1.0)
    
    # [ì§€í‘œ 1] HIR (High-Impact Rate) - í™œë™ì˜ ì§ˆì  í‰ê°€
    # ìˆ˜ì‹: (ê°€ì¤‘ì¹˜ * í’ˆì§ˆ) / ì´ í™œë™
    df['HIR_Raw'] = df['W_Act'] * 1.0 # í’ˆì§ˆ ì ìˆ˜ëŠ” 1.0 ê¸°ë³¸ê°’ ì²˜ë¦¬
    
    # [ì§€í‘œ 2] RTR (Relationship Temp) - ì‹œê°„ ê°ì‡  ë¡œì§
    # ìˆ˜ì‹: Sentiment * exp(-lambda * t)
    max_date = df['ë‚ ì§œ'].max()
    df['days_diff'] = (max_date - df['ë‚ ì§œ']).dt.days
    df['RTR_Raw'] = np.exp(-cfg['rtr_lambda'] * df['days_diff'])
    
    # [ì§€í‘œ 3] BCR (Behavior Consistency) - í™œë™ ê·œì¹™ì„±
    # ìƒŒë“œë°•ìŠ¤ì—ì„œëŠ” í–‰ë³„ ë¹ˆë„ë¥¼ ì¹´ìš´íŠ¸í•˜ì—¬ ì§‘ê³„ ì‹œì ì— í‘œì¤€í¸ì°¨ ì—°ì‚° ì¤€ë¹„
    df['BCR_Raw'] = 1.0 
    
    # [ì§€í‘œ 4] PHR (Pipeline Health) - ì „ëµ í™œë™ ì—¬ë¶€
    df['PHR_Raw'] = df['activities'].apply(lambda x: 1.0 if x in cfg['phr_acts'] else 0.0)
    
    # [ì§€í‘œ 5] FGR (Field Growth Rate) - Qì™€ Pì˜ ë°¸ëŸ°ìŠ¤
    # ì§‘ê³„ ì‹œì ì—ì„œ Q(60%) + P(40%) ê°€ì¤‘ì¹˜ ì ìš© ì˜ˆì •
    
    # [ì§€í‘œ 6] PI (Prescription Index) - ë‚œì´ë„ ë³´ì • ì„±ê³¼ì§€ìˆ˜
    # ìˆ˜ì‹: ê°€ì¤‘Rx * 0.7 + ì„±ì¥ë¥  * 0.3
    df['PI_Raw'] = df['ì²˜ë°©ìˆ˜ëŸ‰'] * df['W_Seg']
    
    return df

# --- [3. ì‚¬ì´ë“œë°”: 6ëŒ€ ì§€í‘œ ì •ë°€ ì „ëµ ì„¤ì •] ---
with st.sidebar:
    st.header("âš™ï¸ 6ëŒ€ ì§€í‘œ ë§ˆìŠ¤í„° ë¡œì§ ì„¤ì •")
    
    # 1. HIR ì„¤ì •
    with st.expander("1. HIR (í™œë™ ê°€ì¤‘ì¹˜)", expanded=True):
        w_pt = st.slider("PT(ì„¤ëª…íšŒ)", 1.0, 5.0, 3.5, 0.1)
        w_demo = st.slider("ì‹œì—°(Demo)", 1.0, 5.0, 3.0, 0.1)
        w_close = st.slider("í´ë¡œì§•(Closing)", 1.0, 5.0, 4.0, 0.1)
        w_visit = st.slider("ì¼ë°˜ëŒ€ë©´(Visit)", 1.0, 5.0, 2.0, 0.1)
        HIR_W = {'PT': w_pt, 'ì‹œì—°': w_demo, 'í´ë¡œì§•': w_close, 'ëŒ€ë©´': w_visit, 
                 'ë‹ˆì¦ˆí™˜ê¸°': 1.5, 'ì»¨íƒ': 1.2, 'ì ‘ê·¼': 1.0, 'í”¼ë“œë°±': 1.0}

    # 2. RTR ì„¤ì •
    with st.expander("2. RTR (ê´€ê³„ ì˜¨ë„ ê°ì‡ )"):
        r_lam = st.number_input("ê°ì‡ ìƒìˆ˜(Î»)", 0.001, 0.100, 0.035, format="%.3f", help="ê°’ì´ í´ìˆ˜ë¡ ê´€ê³„ê°€ ë¹¨ë¦¬ ì‹ìŒ")
        
    # 3. PHR ì„¤ì •
    with st.expander("3. PHR (íŒŒì´í”„ë¼ì¸ ê¸°ì¤€)"):
        phr_list = st.multiselect("ì „ëµ í™œë™(Next Action) ì •ì˜", 
                                 options=['PT', 'ì‹œì—°', 'í´ë¡œì§•', 'ë‹ˆì¦ˆí™˜ê¸°', 'ëŒ€ë©´'], 
                                 default=['PT', 'ì‹œì—°', 'í´ë¡œì§•'])

    # 4. FGR ì„¤ì •
    with st.expander("4. FGR (ì‹œì¥ì§€ë°°ë ¥ ê°€ì¤‘ì¹˜)"):
        fgr_q_ratio = st.slider("ì²˜ë°©ìˆ˜ëŸ‰(Q) ë°˜ì˜ë¹„ì¤‘", 0.0, 1.0, 0.6)
        
    # 5. PI ì„¤ì •
    with st.expander("5. PI (ë³‘ì› ë‚œì´ë„ ë³´ì •)"):
        w_tertiary = st.number_input("ìƒê¸‰ì¢…í•© ê°€ì¤‘ì¹˜", 1.0, 2.0, 1.5)
        w_general = st.number_input("ì¢…í•©ë³‘ì› ê°€ì¤‘ì¹˜", 1.0, 2.0, 1.2)
        PI_W = {'ìƒê¸‰ì¢…í•©': w_tertiary, 'ì¢…í•©ë³‘ì›': w_general, 'ì¼ë°˜ì˜ì›': 1.0, 'ì•½êµ­/ê¸°íƒ€': 0.8}

    CONFIG = {
        'hir_weights': HIR_W, 'rtr_lambda': r_lam, 
        'phr_acts': phr_list, 'fgr_q_w': fgr_q_ratio, 'pi_weights': PI_W
    }

# --- [4. ë©”ì¸ í™”ë©´: ë‹¤ì¤‘ íŒŒì¼ í†µí•© ë° ë§¤í•‘] ---
st.title("ğŸ§ª SFE Agile Sandbox V13.1")
st.markdown("##### [ì •ì œ] ë‹¤ì¤‘ íŒŒì¼ í†µí•© ë° í‘œì¤€í™” â” [ì „ëµ] ë§ˆìŠ¤í„° ë¡œì§ ì£¼ì… â” [ë°°í¬] ë¹Œë”ìš© CSV ì¶”ì¶œ")

if 'clean_master' not in st.session_state:
    st.session_state.clean_master = None

with st.expander("ğŸ“‚ STEP 1. ë°ì´í„° ì„ íƒ ë° í†µí•©", expanded=True):
    # ìë™ìœ¼ë¡œ ë°ì´í„° í´ë” ìŠ¤ìº”
    data_dirs = ['data/sales', 'data/targets', 'data/crm']
    available_files = []
    for d in data_dirs:
        if os.path.exists(d):
            files = glob.glob(os.path.join(d, "*.csv")) + glob.glob(os.path.join(d, "*.xlsx"))
            available_files.extend(files)
    
    st.info(f"ğŸ” ì‹œìŠ¤í…œì´ {len(available_files)}ê°œì˜ ë¶„ì„ ê°€ëŠ¥í•œ íŒŒì¼ì„ ì°¾ì•˜ìŠµë‹ˆë‹¤.")
    
    selected_files = st.multiselect(
        "ë¶„ì„ì— í¬í•¨í•  íŒŒì¼ì„ ì„ íƒí•˜ì„¸ìš”", 
        options=available_files,
        default=available_files[:1] if available_files else [],
        help="data í´ë” ë‚´ì˜ íŒŒì¼ë“¤ì´ ìë™ìœ¼ë¡œ í‘œì‹œë©ë‹ˆë‹¤."
    )
    
    # ì¶”ê°€ ì—…ë¡œë“œ ê¸°ëŠ¥ ìœ ì§€
    uploaded_files = st.file_uploader("ê·¸ ì™¸ ì¶”ê°€ë¡œ ì—…ë¡œë“œí•  íŒŒì¼ì´ ìˆë‹¤ë©´ ì„ íƒí•˜ì„¸ìš”", type=["csv", "xlsx"], accept_multiple_files=True)
    
    all_data_sources = selected_files + (uploaded_files if uploaded_files else [])
    
    if all_data_sources:
        # íŒŒì¼ í†µí•© ë¡œì§
        df_list = []
        for f in all_data_sources:
            if isinstance(f, str): # ê²½ë¡œ ë¬¸ìì—´ì¸ ê²½ìš° (ìë™ íƒìƒ‰)
                if f.endswith('.xlsx'):
                    df_list.append(pd.read_excel(f))
                else:
                    df_list.append(pd.read_csv(f))
            else: # ì—…ë¡œë“œëœ íŒŒì¼ ê°ì²´ì¸ ê²½ìš°
                if f.name.endswith('.xlsx'):
                    df_list.append(pd.read_excel(f))
                else:
                    df_list.append(pd.read_csv(f))
        
        raw_df = pd.concat(df_list, ignore_index=True)
        st.success(f"âœ… ì´ {len(all_data_sources)}ê°œ ë°ì´í„° ì†ŒìŠ¤ í†µí•© ì™„ë£Œ (ì´ {len(raw_df):,}ê±´)")
        
        # ë§¤í•‘ í¼
        cols = raw_df.columns.tolist()
        mapping_config = load_mapping_config()
        
        with st.form("master_mapping"):
            st.info("ğŸ’¡ ì‹œìŠ¤í…œì´ ë“±ë¡ëœ ë³„ëª… ì‚¬ì „ì„ ê¸°ë°˜ìœ¼ë¡œ ì»¬ëŸ¼ì„ ìë™ ë§¤í•‘í–ˆìŠµë‹ˆë‹¤. ì˜¬ë°”ë¥´ì§€ ì•Šë‹¤ë©´ ì§ì ‘ ì„ íƒí•˜ì„¸ìš”.")
            c1, c2, c3 = st.columns(3)
            with c1:
                m_br = st.selectbox("ì§€ì (Branch)", options=cols, index=find_best_match("ì§€ì ", cols, mapping_config))
                m_rep = st.selectbox("ë‹´ë‹¹ì(Rep)", options=cols, index=find_best_match("ì„±ëª…", cols, mapping_config))
            with c2:
                m_hosp = st.selectbox("ë³‘ì›ëª…(Hospital)", options=cols, index=find_best_match("ë³‘ì›ëª…", cols, mapping_config))
                m_pd = st.selectbox("í’ˆëª©(Product)", options=cols, index=find_best_match("í’ˆëª©", cols, mapping_config))
                m_val = st.selectbox("ì‹¤ì (Amount)", options=cols, index=find_best_match("ì²˜ë°©ê¸ˆì•¡", cols, mapping_config))
                m_tgt = st.selectbox("ëª©í‘œ(Target)", options=cols, index=find_best_match("ëª©í‘œê¸ˆì•¡", cols, mapping_config))
            with c3:
                m_act = st.selectbox("í™œë™(Activity)", options=cols, index=find_best_match("activities", cols, mapping_config))
                m_dt = st.selectbox("ë‚ ì§œ(Date)", options=cols, index=find_best_match("ë‚ ì§œ", cols, mapping_config))
                m_seg = st.selectbox("ì„¸ê·¸ë¨¼íŠ¸(Segment)", options=cols, index=find_best_match("segment", cols, mapping_config))
            
            learn_mapping = st.checkbox("ì´ ë§¤í•‘ ì •ë³´ë¥¼ ë³„ëª… ì‚¬ì „ì— ì¶”ê°€í•˜ì—¬ í•™ìŠµí•˜ê¸°", value=True)
            
            if st.form_submit_button("ğŸš€ ë§ˆìŠ¤í„° ë¡œì§ ì ìš© ë° ë°ì´í„° í‘œì¤€í™”"):
                # í•™ìŠµ ëª¨ë“œ: ìƒˆë¡œìš´ ë³„ëª…ì´ë©´ ì €ì¥
                if learn_mapping:
                    updated = False
                    mapping_pairs = [("ì§€ì ", m_br), ("ì„±ëª…", m_rep), ("ë³‘ì›ëª…", m_hosp), ("í’ˆëª©", m_pd), ("ì²˜ë°©ê¸ˆì•¡", m_val), ("ëª©í‘œê¸ˆì•¡", m_tgt), ("activities", m_act), ("ë‚ ì§œ", m_dt), ("segment", m_seg)]
                    for key, val in mapping_pairs:
                        if key in mapping_config and val not in mapping_config[key]:
                            mapping_config[key].append(val)
                            updated = True
                    if updated:
                        save_mapping_config(mapping_config)
                        st.toast("ğŸ§  ì‹œìŠ¤í…œì´ ìƒˆë¡œìš´ ì»¬ëŸ¼ ë§¤í•‘ì„ í•™ìŠµí–ˆìŠµë‹ˆë‹¤!", icon="âš¡")

                # ì»¬ëŸ¼ëª… í‘œì¤€í™” (ì•ˆì „í•œ ë§¤í•‘)
                rename_map = {
                    m_br: 'ì§€ì ', m_rep: 'ì„±ëª…', m_hosp: 'ë³‘ì›ëª…', m_pd: 'í’ˆëª©',
                    m_val: 'ì²˜ë°©ê¸ˆì•¡', m_tgt: 'ëª©í‘œê¸ˆì•¡', m_act: 'activities',
                    m_dt: 'ë‚ ì§œ', m_seg: 'segment'
                }
                
                # ì¤‘ë³µëœ ë§¤í•‘ ì œê±° (ë™ì¼í•œ ì›ë³¸ ì»¬ëŸ¼ì´ ë‹¤ë¥¸ ì´ë¦„ìœ¼ë¡œ ë‘ ë²ˆ ë§¤í•‘ë  ë•Œ ë§ˆì§€ë§‰ ê²ƒ ìœ ì§€)
                df_std = raw_df.copy()
                df_std = df_std.rename(columns=rename_map)

                # ì‚¬ìš©ì ì„ íƒ ì»¬ëŸ¼ì„ ìµœìš°ì„ ìœ¼ë¡œ activitiesì— ê°•ì œ ë°˜ì˜
                if m_act in raw_df.columns:
                    df_std['activities'] = raw_df[m_act]

                # í™œë™ëª… ë§¤í•‘ ë³´ì •:
                # rename ì´í›„ ì»¬ëŸ¼ì´ ë°”ë€Œì–´ë„ raw_dfì˜ ì›ë³¸ í™œë™ ì»¬ëŸ¼ì„ ìš°ì„  ì‚¬ìš©í•´ activitiesë¥¼ ë³µêµ¬í•œë‹¤.
                activity_source_cols = []
                if m_act in raw_df.columns:
                    activity_source_cols.append(m_act)
                for col in raw_df.columns:
                    col_str = str(col)
                    col_esc = col_str.encode('unicode_escape').decode()
                    if col_str in ['activities', 'activity', 'Activity'] or ('\\ud65c\\ub3d9' in col_esc):
                        activity_source_cols.append(col)
                activity_source_cols = list(dict.fromkeys(activity_source_cols))

                if activity_source_cols:
                    act_series = pd.Series(np.nan, index=raw_df.index, dtype='object')
                    for col in activity_source_cols:
                        src = raw_df[col]
                        src = src.where(src.notna() & (src.astype(str).str.strip() != ''), np.nan)
                        act_series = act_series.fillna(src)
                    df_std['activities'] = act_series

                # ì„ íƒí•œ activity ì»¬ëŸ¼ì„ "ë³‘í•©" í˜•íƒœë¡œ ë³´ê°•:
                # CRM í–‰ì—ë§Œ ìˆëŠ” í™œë™ê°’ì„ í‚¤ ê¸°ì¤€ìœ¼ë¡œ ì „ì²´ í–‰ì— ì „íŒŒí•œë‹¤.
                if 'activities' in df_std.columns:
                    df_std['activities'] = df_std['activities'].astype('object')
                    df_std['activities'] = df_std['activities'].where(
                        df_std['activities'].notna() & (df_std['activities'].astype(str).str.strip() != ''),
                        np.nan
                    )

                    # ì›” í‚¤ ìƒì„± (ë‚ ì§œ/í™œë™ì¼ì/ëª©í‘œì›”/ì›” ì¤‘ ê°€ìš© ì»¬ëŸ¼ ì‚¬ìš©)
                    month_src = None
                    for c in ['ë‚ ì§œ', 'í™œë™ì¼ì', 'ëª©í‘œì›”', 'ì›”']:
                        if c in df_std.columns:
                            month_src = c
                            break
                    if month_src is not None:
                        parsed_month = pd.to_datetime(df_std[month_src], errors='coerce').dt.month
                        if parsed_month.notna().sum() <= len(df_std) * 0.3:
                            parsed_month = pd.to_numeric(df_std[month_src], errors='coerce')
                        df_std['__act_month'] = parsed_month
                    else:
                        df_std['__act_month'] = np.nan

                    key_candidates = ['ì§€ì ', 'ì„±ëª…', 'í’ˆëª©', 'ë³‘ì›ID', '__act_month']
                    merge_keys = [k for k in key_candidates if k in df_std.columns]
                    merge_keys = [k for k in merge_keys if not df_std[k].isna().all()]

                    if merge_keys:
                        donors = df_std[df_std['activities'].notna()].copy()
                        if not donors.empty:
                            valid_keys = [k for k in merge_keys if donors[k].notna().sum() > 0 and len(donors[donors[k] != 'nan']) > 0]
                            if valid_keys:
                                for k in valid_keys:
                                    if donors[k].dtype == object:
                                        donors[k] = donors[k].astype(str).str.strip().replace('nan', np.nan)
                                        df_std[k] = df_std[k].astype(str).str.strip().replace('nan', np.nan)
                                
                                act_map = (
                                    donors.groupby(valid_keys)['activities']
                                    .agg(lambda s: s.mode().iat[0] if not s.mode().empty else s.iloc[0])
                                    .reset_index()
                                    .rename(columns={'activities': '__activities_mapped'})
                                )
                                df_std = df_std.merge(act_map, on=valid_keys, how='left')
                                df_std['activities'] = df_std['activities'].fillna(df_std['__activities_mapped'])
                                df_std = df_std.drop(columns=['__activities_mapped'])

                    if '__act_month' in df_std.columns:
                        df_std = df_std.drop(columns=['__act_month'])

                if 'activities' in df_std.columns and df_std['activities'].notna().sum() == 0:
                    st.warning("í™œë™(Activity) ë§¤í•‘ ê²°ê³¼ê°€ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤. CRMì˜ 'í™œë™ëª…' ì»¬ëŸ¼ ì„ íƒ ì—¬ë¶€ë¥¼ í™•ì¸í•˜ì„¸ìš”.")
                
                # ë””ë²„ê¹…: ë§¤í•‘ ê²°ê³¼ í™•ì¸
                if 'ë‚ ì§œ' not in df_std.columns:
                    st.error(f"âŒ 'ë‚ ì§œ' ì»¬ëŸ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. (ì„ íƒëœ ì›ë³¸: {m_dt})")
                    st.write("í˜„ì¬ ì»¬ëŸ¼ ë¦¬ìŠ¤íŠ¸:", df_std.columns.tolist())
                    st.stop()

                df_std['ë‚ ì§œ'] = pd.to_datetime(df_std['ë‚ ì§œ'], errors='coerce')
                # ê²°ì¸¡ì¹˜ ì œê±°
                df_std = df_std.dropna(subset=['ë‚ ì§œ'])
                
                # ì²˜ë°©ìˆ˜ëŸ‰ ë¶€ì¬ ì‹œ ì²˜ë°©ê¸ˆì•¡ ê¸°ë°˜ ê°€ìƒ ìƒì„± (ë¶„ì„ìš©)
                if 'ì²˜ë°©ìˆ˜ëŸ‰' not in df_std.columns:
                    amt = pd.to_numeric(df_std['ì²˜ë°©ê¸ˆì•¡'], errors='coerce')
                    qty = (amt / 1000).replace([np.inf, -np.inf], np.nan).fillna(0)
                    df_std['ì²˜ë°©ìˆ˜ëŸ‰'] = qty.astype(int)
                if 'ëª©í‘œê¸ˆì•¡' in df_std.columns:
                    df_std['ëª©í‘œê¸ˆì•¡'] = pd.to_numeric(df_std['ëª©í‘œê¸ˆì•¡'], errors='coerce').fillna(0)
                
                # ğŸ’¡ 6ëŒ€ ì§€í‘œ ë§ˆìŠ¤í„° ì—”ì§„ ê°€ë™
                st.session_state.clean_master = calculate_master_engine(df_std, CONFIG)
                
                # [ìë™ ì €ì¥] ë¹Œë” ì—°ë™ì„ ìœ„í•´ ë¬¼ë¦¬ì  íŒŒì¼ë¡œ ì¦‰ì‹œ ì €ì¥
                output_dir = 'output/processed_data'
                if not os.path.exists(output_dir):
                    os.makedirs(output_dir)
                
                # ê°€ê³µ ë°ì´í„° íŒŒì¼ëª… ê·œì¹™ ì ìš©
                save_path = get_unique_filename(output_dir, 'standardized_sales', 'csv')
                st.session_state.clean_master.to_csv(save_path, index=False, encoding='utf-8-sig')
                st.success(f"âœ¨ ëª¨ë“  ë¶„ì„ ë¡œì§ì´ ì£¼ì…ë˜ì—ˆìœ¼ë©°, '{save_path}'ë¡œ ìë™ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")

# --- [5. ë°ì´í„° ê²€ì¦ ë° ë¦¬í¬íŠ¸ ë¹Œë” ì—°ë™] ---
if st.session_state.clean_master is not None:
    df = st.session_state.clean_master
    st.divider()
    
    st.subheader("ğŸ“Š STEP 2. ì „ëµ ë°ì´í„° ê²€ì¦ ë° ì¶”ì¶œ")
    
    # íƒ­ ìƒì„±
    tab1, tab2 = st.tabs(["ğŸ“Š 1ì°¨ ê²°ê³¼ í…œí”Œë¦¿", "ğŸ—ºï¸ ì „êµ­ë³‘ì› ì§€ë„ ë·°"])
    
    with tab1:
        # ì§€í‘œ ìš”ì•½ ì‹œê°í™” (Ad-hoc)
        t1, t2 = st.columns([1, 3])
        with t1:
            st.write("ğŸ” ì¦‰ì„ ë°ì´í„° í™•ì¸")
            view_dim = st.selectbox("ë¶„ì„ ì°¨ì›", ['ì§€ì ', 'ì„±ëª…', 'í’ˆëª©'])
            view_metric = st.selectbox("ë¶„ì„ ì§€í‘œ", ['ì²˜ë°©ê¸ˆì•¡', 'HIR_Raw', 'RTR_Raw', 'PHR_Raw'])
        with t2:
            view_df = df.groupby(view_dim)[view_metric].mean().reset_index()
            fig = px.bar(view_df, x=view_dim, y=view_metric, template='plotly_white', color=view_metric)
            st.plotly_chart(fig, use_container_width=True)
    
        # ğŸ“¦ ë¦¬í¬íŠ¸ ë¹Œë”ìš© íŒŒì¼ ì¶”ì¶œ ì„¹ì…˜
        st.info("ğŸ“¦ **ë¦¬í¬íŠ¸ ë¹Œë” ë° ìµœì¢… ê²°ê³¼ë¬¼ ìƒì„±**")
        final_cols = ['ì§€ì ', 'ì„±ëª…', 'ë³‘ì›ëª…', 'í’ˆëª©', 'ì²˜ë°©ê¸ˆì•¡', 'ëª©í‘œê¸ˆì•¡', 'ì²˜ë°©ìˆ˜ëŸ‰', 'activities', 'segment', 'ë‚ ì§œ', 'HIR_Raw', 'RTR_Raw', 'PHR_Raw', 'PI_Raw']
        export_df = df[[c for c in final_cols if c in df.columns]]
        
        c1, c2 = st.columns(2)
        with c1:
            csv_out = export_df.to_csv(index=False).encode('utf-8-sig')
            st.download_button(
                label="ğŸ“¥ í‘œì¤€ CSV ë‹¤ìš´ë¡œë“œ",
                data=csv_out,
                file_name="standardized_sales.csv",
                mime="text/csv",
                help="ì´ íŒŒì¼ì„ ë‹¤ìš´ë¡œë“œí•˜ì—¬ ë³„ë„ë¡œ ë³´ê´€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
            )
        
        with c2:
            if st.button("ğŸ› ï¸ ìµœì¢… ì „ëµ ë¦¬í¬íŠ¸(HTML) ìƒì„±", type="primary"):
                with st.spinner("ğŸš€ ê³ ì°¨ì› ë¶„ì„ ì—”ì§„ ê°€ë™ ì¤‘..."):
                    try:
                        # report_builder_v12ì˜ ë¡œì§ í˜¸ì¶œ (í˜„ì¬ ìŠ¬ë¼ì´ë” ì„¤ì • ë°˜ì˜)
                        from report_builder_v12 import build_final_reports
                        output_file = build_final_reports(external_config=CONFIG)
                        
                        if output_file:
                            st.success(f"âœ… ë¦¬í¬íŠ¸ ìƒì„± ì™„ë£Œ! \n\n íŒŒì¼ ìœ„ì¹˜: `{output_file}`")
                            
                            # ìƒì„±ëœ HTML íŒŒì¼ì„ ë°”ë¡œ ë‹¤ìš´ë¡œë“œí•  ìˆ˜ ìˆê²Œ ì œê³µ
                            with open(output_file, "rb") as f:
                                st.download_button(
                                    label="ğŸš€ ìƒì„±ëœ ëŒ€ì‹œë³´ë“œ ë°”ë¡œ ë‹¤ìš´ë¡œë“œ",
                                    data=f,
                                    file_name=os.path.basename(output_file),
                                    mime="text/html"
                                )
                    except Exception as e:
                        st.error(f"âŒ ë¦¬í¬íŠ¸ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        
        st.divider()
        st.dataframe(export_df.head(20))

    with tab2:
        render_hospital_map_tab(df=df, current_dir=current_dir)
